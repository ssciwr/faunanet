{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(str(Path.home() / Path(\"Development\") / \"iSparrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iSparrow import PreprocessorBase\n",
    "from iSparrow import ModelBase\n",
    "from iSparrow import SparrowRecording\n",
    "from iSparrow import SpeciesPredictorBase\n",
    "import iSparrow.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tests.set_up_sparrow_env as sp\n",
    "from watchdog.events import LoggingEventHandler, FileSystemEventHandler\n",
    "from watchdog.observers import Observer\n",
    "import time\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "import yaml\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a mock install of sparrow. will be invisible in the future\n",
    "sp.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalysisEventHandler(FileSystemEventHandler):\n",
    "    def __init__(self, callback: callable, wait_event):\n",
    "        self.wait_event = wait_event\n",
    "        self.callback = callback\n",
    "\n",
    "    def on_created(self, event):\n",
    "        if Path(event.src_path).is_file() and Path(event.src_path).suffix == \".wav\":\n",
    "            self.wait_event.wait()\n",
    "            self.callback(event.src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Watcher:\n",
    "\n",
    "    def _load_model(self):\n",
    "        self.preprocessor_module = utils.load_module(\n",
    "            \"ppm\", self.model_dir / Path(self.model_name) / \"preprocessor.py\"\n",
    "        )\n",
    "\n",
    "        self.model_module = utils.load_module(\n",
    "            \"md\", self.model_dir / Path(self.model_name) / \"model.py\"\n",
    "        )\n",
    "\n",
    "    def _write_config(self):\n",
    "\n",
    "        with open(self.output / \"config.yml\", \"w\") as ymlfile:\n",
    "            yaml.safe_dump(self.config, ymlfile)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        indir: str,\n",
    "        outdir: str,\n",
    "        model_dir: str,\n",
    "        model_name: str,\n",
    "        watch_in_background: bool = False,\n",
    "        preprocessor_config: dict = {},\n",
    "        model_config: dict = {},\n",
    "        recording_config: dict = {},\n",
    "        species_predictor_config: dict = {},\n",
    "    ):\n",
    "\n",
    "        # set up data to use\n",
    "        self.input = Path(indir)\n",
    "        self.outdir = outdir\n",
    "        self.output = Path(self.outdir) / Path(datetime.now().strftime(\"%y%m%d_%H%M%S\"))\n",
    "        self.output.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        self.model_dir = Path(model_dir)\n",
    "        self.model_name = model_name\n",
    "        self.proprocessor_module = None\n",
    "        self.model_module = None\n",
    "        self.model = None\n",
    "        self.preprocessor = None\n",
    "        self.watch_in_background = watch_in_background\n",
    "        # set up model for analysis\n",
    "        self._load_model()\n",
    "\n",
    "        self.preprocessor = self.preprocessor_module.Preprocessor(**preprocessor_config)\n",
    "\n",
    "        self.model = self.model_module.Model(\n",
    "            model_path=self.model_dir / model_name, **model_config\n",
    "        )\n",
    "\n",
    "        # process config file\n",
    "        self.config = {\n",
    "            \"Analysis\": {\n",
    "                \"input\": str(self.input),\n",
    "                \"output\": str(self.output),\n",
    "                \"model_dir\": str(self.model_dir),\n",
    "                \"watch_in_background\": self.watch_in_background,\n",
    "                \"Preprocessor\": deepcopy(preprocessor_config),\n",
    "                \"Model\": deepcopy(model_config),\n",
    "                \"Recording\": deepcopy(recording_config),\n",
    "                \"SpeciesPredictor\": deepcopy(species_predictor_config),\n",
    "            }\n",
    "        }\n",
    "\n",
    "        self.config[\"Analysis\"][\"Model\"][\"model_name\"] = model_name\n",
    "\n",
    "        self._write_config()\n",
    "\n",
    "        # process species range predictor\n",
    "        if all(name in recording_config for name in [\"date\", \"lat\", \"lon\"]) and all(\n",
    "            recording_config[name] is not None for name in [\"date\", \"lat\", \"lon\"]\n",
    "        ):\n",
    "\n",
    "            model_name == \"birdnet_default\"\n",
    "\n",
    "            # we can use the species predictor\n",
    "            species_predictor = SpeciesPredictorBase(\n",
    "                model_path=self.model_dir / model_name,\n",
    "                **species_predictor_config,\n",
    "            )\n",
    "\n",
    "            recording_config[\"species_predictor\"] = species_predictor\n",
    "\n",
    "        # create recording object\n",
    "        # species predictor is applied here once and then used for all the analysis calls that may follow\n",
    "        self.recording = SparrowRecording(\n",
    "            self.preprocessor, self.model, \"\", **recording_config\n",
    "        )\n",
    "\n",
    "        self.results = []\n",
    "\n",
    "    def change_model(\n",
    "        self,\n",
    "        model_name,\n",
    "        preprocessor_config: dict = {},\n",
    "        model_config: dict = {},\n",
    "    ):\n",
    "\n",
    "        # raise RuntimeError(\"Not yet supported, only untested skeleton code exists\")\n",
    "        # print(\"setting analyzer thread to wait\")\n",
    "        # self.stop()  # reset event flag to false to indicate that the thread should wait\n",
    "\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self._load_model()\n",
    "\n",
    "        self.preprocessor = self.preprocessor_module.Preprocessor(**preprocessor_config)\n",
    "\n",
    "        self.model = self.model_module.Model(\n",
    "            model_path=self.model_dir / model_name, **model_config\n",
    "        )\n",
    "\n",
    "        self.recording.set_analyzer(self.model, self.preprocessor)\n",
    "\n",
    "        # make new output, update config file and write new config file\n",
    "        self.output = Path(self.outdir) / Path(datetime.now().strftime(\"%y%m%d_%H%M%S\"))\n",
    "\n",
    "        self.output.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.config[\"Analysis\"][\"Model\"][\"model_name\"] = model_name\n",
    "\n",
    "        self.config[\"Analysis\"][\"output\"] = str(self.output)\n",
    "\n",
    "        self._write_config()\n",
    "\n",
    "        # print(\"setting analyzer flag to go\")\n",
    "        # self.go_on()\n",
    "\n",
    "    def analyze(self, filename: str):\n",
    "\n",
    "        self.recording.path = filename\n",
    "\n",
    "        self.recording.analyze()\n",
    "\n",
    "        self.results.extend(self.recording.detections)\n",
    "\n",
    "        self.save_results(suffix=Path(filename).stem)\n",
    "\n",
    "    def save_results(self, suffix=\"\"):\n",
    "        pd.DataFrame(self.results).to_csv(self.output / Path(f\"results_{suffix}.csv\"))\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "    ):\n",
    "        def task(e):\n",
    "            e.wait()\n",
    "            observer = Observer()\n",
    "            event_handler = AnalysisEventHandler(self.analyze, self.wait_event)\n",
    "            observer.schedule(event_handler, self.input, recursive=True)\n",
    "            observer.start()\n",
    "\n",
    "            try:\n",
    "                while True:\n",
    "                    time.sleep(1)\n",
    "            except KeyboardInterrupt:\n",
    "                observer.stop()\n",
    "            except Exception:\n",
    "                print(\"Something went wrong\")\n",
    "                observer.stop()\n",
    "            observer.join()\n",
    "\n",
    "        if self.watch_in_background:\n",
    "            self.wait_event = threading.Event()\n",
    "            self.wait_event.set()\n",
    "            self.watcher_thread = threading.Thread(target=task, args=(self.wait_event,))\n",
    "            self.watcher_thread.daemon = True\n",
    "            self.watcher_thread.start()\n",
    "        else:\n",
    "            task()\n",
    "\n",
    "    def stop(self):\n",
    "        if self.watch_in_background and self.watcher_thread.is_alive():\n",
    "            self.wait_event.clear()\n",
    "\n",
    "    def go_on(self):\n",
    "        if self.watch_in_background and self.watcher_thread.is_alive():\n",
    "            self.wait_event.set()\n",
    "\n",
    "    def check_analysis(self):\n",
    "        for filename in self.input.iterdir():\n",
    "            if (\n",
    "                self.output / Path(f\"results_{str(filename.stem)}.csv\").is_file()\n",
    "                is False\n",
    "            ):\n",
    "                self.analyze(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_cfg = {\n",
    "    \"sample_rate\": 48000,\n",
    "    \"overlap\": 0.0,\n",
    "    \"sample_secs\": 3.0,\n",
    "    \"resample_type\": \"kaiser_fast\",\n",
    "}\n",
    "\n",
    "model_cfg = {\n",
    "    \"num_threads\": 1,\n",
    "    \"sigmoid_sensitivity\": 1.0,\n",
    "    \"species_list_file\": None,\n",
    "}\n",
    "\n",
    "recording_cfg = {\n",
    "    \"date\": datetime(year=2022, month=5, day=10),\n",
    "    \"lat\": 35.4244,\n",
    "    \"lon\": -120.7463,\n",
    "    \"species_presence_threshold\": 0.03,\n",
    "    \"min_conf\": 0.25,\n",
    "    \"species_predictor\": None,\n",
    "}\n",
    "\n",
    "species_predictor_cfg = {\n",
    "    \"use_cache\": True,\n",
    "    \"num_threads\": 1,\n",
    "}\n",
    "\n",
    "runner = Watcher(\n",
    "    Path.home() / \"iSparrow_data\",\n",
    "    Path.home() / \"iSparrow_output\",\n",
    "    Path.home() / \"iSparrow/models\",\n",
    "    \"birdnet_default\",\n",
    "    watch_in_background=True,\n",
    "    preprocessor_config=preprocessor_cfg,\n",
    "    model_config=model_cfg,\n",
    "    recording_config=recording_cfg,\n",
    "    species_predictor_config=species_predictor_cfg,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_cfg = {\n",
    "    \"sample_rate\": 48000,\n",
    "    \"overlap\": 0.0,\n",
    "    \"sample_secs\": 3.0,\n",
    "    \"resample_type\": \"kaiser_fast\",\n",
    "}\n",
    "\n",
    "model_cfg = {\n",
    "    \"num_threads\": 1,\n",
    "    \"sigmoid_sensitivity\": 1.0,\n",
    "    \"default_model_path\": Path.home() / \"iSparrow/models/birdnet_default\",\n",
    "}\n",
    "\n",
    "runner.change_model(\n",
    "    \"birdnet_custom\", preprocessor_config=preprocessor_cfg, model_config=model_cfg\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".isparrowrecord",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
